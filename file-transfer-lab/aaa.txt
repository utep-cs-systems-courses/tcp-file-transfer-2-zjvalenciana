like the co-workers were saying we're from the us army combat capabilities development command ccdc uh data and analysis center dac or dac so that's our uh organization and so pretty much what i'm going to go over is our penetration testing methodology and and these are more uh it's not so much like an oauth penetration testing methodology or any other kind of like standardized this one is more so like uh what i've noticed and what i've experienced when i go on a pen test so what i'm calling a pen test or an event is when you know uh an organization in within the army will contract us to go in there and test their system and their systems could be all kinds of things a network a device a vehicle like it's very diverse so pretty much we just got force four phases during our pen test there's the planning phase so this is when we uh well there's a planning phase where we pretty much plan how we're going to test and then once we're on site we we first step we do is it's we call it the discovery phase which is where we're pretty much enumerating scanning and enumerating uh usually a network finding out what's out there what vulnerabilities we can see and then once we find all that then we're going to try to exploit those vulnerabilities that's in the attack phase and then once we can find some vulnerabilities to exploit we keep a listing of all those vulnerabilities and then we create a report and and we have to report that back to the customer both in in a in a document we give them and in a presentation we get so oops okay so a little bit more about the planning phase so that's pretty much when we meet with the project manager stakeholders and agree on vectors to test so they know their system real well and they know uh what they want uh to be tested in their system they want to make sure that their system is you know if there's any vulnerabilities in in its communication protocol that you know that's then they'll tell us like hey we want you to look at this specifically and they'll come up with like a list to tell us and then from that list that they have those those vectors that we agree on to test we create a test plan so then we come up with like pretty much uh usually our test lasts between a week to two weeks and we'll come up with like a daily plan like okay the first day we get there we're gonna you know pretty much meet with the customers probably get access to uh locations we're supposed to be in do stuff like that get credentials if we if we're gonna do any kind of credentialed testing you know so that'll be the first day that we plan on then the second day we're gonna be like well this we just scan all we're just gonna do scanning all that day and go look what's out there and maybe look at to see if any uh any of these uh hosts that we've scanned are vulnerable to any kind of an exploit and then the next day we'll we'll try to you know okay well one of the vectors that they wanted to look at was you know looking at uh particular protocol so then we'll try to see if we can find any vulnerabilities there so that's pretty much like how we're creating a plan a daily you know what we're going to do throughout the when we're out there on an event and then part also the part of the planning phase is the you know we have to get computers uh procure hardware software depending on what we're testing uh it's to to take with us to the test so that's the planning phase so like once we're there and we're it's like the first day we'll usually start scanning that and that's this is like what the project is mostly about this face here and that's where we're going to like run scanning tools to get a listing of hosts and services and from those hosts and services we'll see we also have vulnerability scanners we use to see if any of those services are vulnerable to known exploits and and we also like to create like a visual mapping of the network uh including our attackers including ourselves as attackers right on sitting on their network and then the next phase obviously like i said before is the attack phase where we leverage all the knowledge we gained from the scanning and the enumeration and try to actually perform exploits of those vulnerabilities and if we're successful in some of those exploits we document them because we're going to have to report you know we're going to have to create a report and a presentation later on to tell the customer and if we uh you know left any kind of you know bot uh like a trojan or anything on their machines we gotta clean all that up right we gotta take all that off because some of these uh some of these systems we use are actually production systems so they're actually being used you know and we can't leave our you know little hacker artifacts on there and then finally it's the reporting phase where we take all of those exploits that we've documented and uh usually we like before when we're still on site the last day we'll give them uh what we call an emerging results brief which is it's not a very in-depth look at the at the exploits or the vulnerabilities that we've found because we haven't really had time to analyze any of that but it's just a it's kind of a first look at what we found and then once we come back to a white sands missile missile range then we can like perform a little bit more in that in-depth analysis to understand the impact of these uh exploits that we've actually uncovered and that's when we create uh documentation to to show the customer the actual impact of these vulnerabilities to make them understand like well this is this is a very serious vulnerability you have in your system and you know they could like how much it could cost cost them so the problem that we're going to go over one problem that we have is the scanning is our scanning and enumeration phase is not consistent so kind of like you see the that little bullseye with the arrows all over it some some some of our analysts get a little closer to the bullseye than others and that's because there's no uh standardized uh not so much standardized way everybody kind of does it their own way we have some tools that we all run but like we would still like to get a little bit more uh streamlined and standardized when we perform this this first phase and this first phase you know it impacts all the the attack phase and all you know ultimately impacts if we find vulnerabilities or not so since no two analysts necessarily enumer scan and enumerate the exact same way we would like a tool to help us streamline this and standardize this part because like i was saying before we missed some vulnerabilities that's not good we you know that's a customer doesn't know that they're there or if uh we didn't scan we didn't perform the scanning and enumeration phase correctly maybe it might take a lot a longer time to find vulnerabilities because we didn't know they were there in an earlier phase right so that's pretty much our the problem that we have so in the discovery phase we running scanning tools to get a list of hosts and services we we use mostly the same uh so we use nmap nmap is a is a command line tool that is available that's free that's open source but when we use nmap to scan a network we usually use the same kinds of switches you know the same the same settings the same arguments to nmap and sometimes like using different arguments could help uncover other vulnerabilities so currently we all kind of use the same ones there's no real variation there which we would like to kind of to do going going and going going ahead in the future another step is the running vulnerability scanners to see what vulnerabilities exist so this isn't really consistent at all and it all really depends on what hosts are out there so are they windows hosts are they linux hosts are they old xp windows you know like is it a server running is it a cisco switch router you know like and so all those different uh operating systems and computers could really change the type of vulnerability scanners that you'd use so really currently today we use this tool called nessus and that that's a pretty good vulnerability scanner but still we would like to get a little bit more uh a little bit more like detailed in our vulnerability scanners so nessus pretty much can scan everything all kinds of operating stuff that's what it's that's one of its capabilities is it can scan all kinds of operating systems all kinds of machines but we would like to get a little bit more like maybe use a scanner that's only for uh windows machines if we know that there's windows machines out there so we really don't do that unless uh unless one of an unless an analyst knows to you know and is familiar with the tool so what we need is what we're calling uh the c tool so the scanning and enumeration tool scanning enumeration automation tool so pretty much we want a tool that will accept a white list and a black list of ips because usually we're we test a lot of networks which have you know prove ip each host is uh identified by an ip so what a white list is is just though you know they'll tell us okay these are the hosts that we want you to test and here's the list of ips of those hosts so that would be the white list but sometimes sitting on that network are hosts which they're like do not touch these hosts do not scan them do not do anything to them so that that would be the blacklist right and then uh we'd also like input to the tool to be like me uh some of the actual uh like n map is an example so those are the switches that would go into nmap that we'd like to so when we run nmap it knows to take in those arguments when it performs its scan but we'd also like to not not just have arguments to nmap but other tools as well other command line tools that we have available to us so that's the first step is put it is the this tool that you'll create will take in these arguments and then we wanted of course to like start running this tool so this example here just shows an nmap scan so it would send out its scanning you know send out the nmap scan to a particular uh network that we're testing and then get all those results and and and keep them for us so in in here i have listed some of the other tools some of the other tools that we use so that we would like to the c tool to be able to automate so like nessus like i was saying before durb so durb go buster that's pretty much uh url fuzzing so if any of these machines have our web servers and we want to go and see what uh pages or what content is or is that web server uh making available you could use durb to go uh to go pretty much brute force uh words common pages to go see if any of that's out there cutie cap is another tool which takes screenshots of actual web pages that a web server could uh serve out nicto is another tool which is pretty much a vulnerability scanner kind of similar to nessus but just specifically for web websites smb map enum for linux crack map exec all those uh will find they'll find vulnerabilities in windows systems smb map obviously is specifically for an smb service so if a computer has smb like a linux or a windows machine could have smb service on it so that you could use it for that but enough for limits crack map exec those are kind of used more so for windows machines so we'd like this c tool to to kind of run through all the nmap nessus all that on a particular network all automated without us having to go run you know particular command the nessus command derp command cutie cap command right and then we would like to to get an out so the c tool took in the input of a white blacklist and all the arguments to the tools it's perform the scan and then we would like uh this tool to output all of the results into an xml file in this xml file because we have another tool to visualize net the network and that's what we would want this tool to to output is an xml file where we could import that into our other tools so we can visualize the network see all of the vulnerabilities or all of the services or all of the data that pretty much all those other previous tools found and then of course we want this tool to be extensible so if we decide to add so i listed some tools uh or sub tools right that this tool will automate so if we wanted to add another another tool uh for example let's say a custom python script that i that i created so it's a it lets hypothetically it could be like a network where the nodes communicate through a specific protocol that is not commercially available that was created by the you know by the army so they so these two computers talk in a protocol that's very uh customized and let's say i have a script that i built to to understand that protocol i would like to be able to add that to this tool easily and then i would like the tool to run in parallel so like if two if i can run two commands at once i would like the tool to do that because some of these depending if like if the network's really large you know it's like nmap could take a very long time and so if you're running it serially you're having to wait till nmap completes and to run the other tool but if i can run something else while nmap is still running i'd like to do that right because this it would save us time and then we'd like to keep some kind of logging to see like what ran when uh you know so we could you know understand like well okay uh this why didn't i see any anything from this tool although i know that this service exists on a host oh well uh the nmap uh com the nmap command didn't complete so when that other command ran it didn't know that that smb was there because they would only know smb was there from the nmap results right so that's kind of a high level uh a quick overview of what we kind of do and what what we need so i guess right now we'll take some questions from you guys uh i'm gonna have to drop off right now but i'll come back towards the end uh damien and alexis can handle your questions so elsa thank you thank you we're gonna go over the list of concerns uh we have a total of six teams uh let me go over the representative uh for team one we have leslie uh for team two we have stephen uh for team three we have lester team four we have jacob for team five we have jennifer team six we have eduardo so um for all the representatives if you could uh turn on your web camera so that we could see you guys that will be great um let's start with let me pull up my list so we have a list of concerns let's go ahead and start with input that would be team one leslie hear me yes okay good morning so um after looking at the introduction to the um tool we were thinking about you know specific concerns or more of a specific idea and questions in terms of what input are we going to be supporting and so i'm going to be reading off of the list of concerns that the whole class came up with so for question number one what is a standardized input file [Applause] yeah so i think a standard input file would be um the list of tools that you have available so like um and they could be maybe let's say different categories right so vince was describing the process that we follow right so we start with enumeration right so we have let's say several enumeration tools that we run you know that are standard such as you know nmap uh nessus nicto that we look at right so we we look at these hosts we scan ports and we identify different services that are that it's running um and then we have let's say other tools you know so that way if we come across a server or a host that's running a web server like apache um or something else you know we might have tools like burp suite or a wasp zap right so specific tools based on what you see on the hosts so an input file could have let's say the tools and the different parameters and flags because a lot of these are command line tools a lot of these have different flags and different parameters you know you can um so the enumeration ones they might have like you know a flag to specify which ip addresses you want to do and let's say you know maybe they have default scripts so it can do a little bit more on its own so just different flags and parameters on how to run the tool um i think that would all be contained within a configuration file that way we can go in and uh we have the flexibility to add in tools and you know different flags and parameters different lists you know based on those parameters does that answer your question yeah so i have any oh sorry um uh what i want to say is that some of the questions might have been answered uh during the presentation so what i asked um it represented if reading out the question and you know the question has been answered instead of asking our clients to repeat uh themselves what we're gonna do is that uh please try to answer that question uh based on what you have learned from the presentation so that our clients can validate your understanding okay okay go ahead and then um i am going to move over to question number two i know that we had slightly covered senatorized input file i just wanted to see if the clients had a little bit more to add to it the question number two is in the requirements document some of the mentioned tools might require a white list or a black list of ip addresses and we slightly covered it in the presentation but what other inputs should we support for the other tools as well so damian uh correct me if i'm wrong i think the inputs will be taken in that input file so depending on whatever tools are supported like the ones that were mentioned in the presentation so the inputs will depend on what kind of flags or options that each tool has like nmap if you want to do like dash p defines the port so depending on what inputs the other tools take those would be there also in the input file under you know the name so end my colon and then whatever flags and numbers i don't know if that was answers your question a bit okay and then i think this would be a little bit more of a follow-up question in terms of extensibility and adding more tools um i guess more of a note for us of how can we um create a useful tool to also support other input files once we start adding things and then for question number three it says input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced [Applause] right so i think what we would want to do is um i think this kind of goes into like the logging we you know we want immediate feedback if a tool is not able to run if it encounters an error if um you know there is a let's say in the we're in you know we go into the configuration file the standard standardized input file we want to add a tool and um you know i mistyped you know one of the parameters or you know i misspelled something you know i would like this tool to then you know give me that output so i can see it so i can debug it myself right it's not the tool's fault that you know i misspelled something in the you know input file you know but it should help me and tell me you know um where it errored out so that way i can go and debug it so i don't think it's the responsibility of the tool to yeah immediate feedback i don't think it's up to the tool to debug it for me right but rather still tell me give me some kind of visual feedback of what the issue is you know as far as um if something wasn't you know validated okay right and then for that one um we would go more into you know immediate feedback and clear feedback so we can so the tool can actually support you guys through that process of debugging and then for question number four what options would you allow or would you like for the automation process besides the input needed to run the tools for example choosing which tools to use and setting the number of threads to run in parallel [Applause] yeah i think we would definitely want things like that you know specifying the number of threads the um maybe the amount of uh i'd say the order the sequence right i think that the tool should have some logic um in the way that it runs the tools right so you know i was kind of describing where you come across you know some hosts that have you know web servers you might want to run certain tools and you might want to you know that might reveal something else you might want to do like use you know something to um you know there's a tool that can screenshot a web page you know and that's definitely something that we run if we encounter a website it should kind of have that logic to you know if it finds you know web server do these things run these other tools and try and get further information is that gonna answer the question yes um and then for the next question in the document um the document mentioned that commands and ip addresses list would be given through a standardized list please elaborate on how you would like this function to work different tools accept different types of files for example nmap uses an nse file that might call different tools at the same time what if any are the specific preferences for the standardized file so i think this question was briefly answered um i don't know if you would like to add a little bit more to it it kind of merges over with the first question which was specifically about standardized files supported by the specific tools [Applause] right yeah so yeah it ties directly to the first question and the the answer to it um but you know with a lot of these files like i mean a lot of them are already kind of uh like for example a white list or a blacklist right it's just gonna be like a one single file that has a list you know maybe new line separated of ips right and the tool already will accept it so this tool won't be parsing through any of those input files you know for a specific tool or the arguments that are passed into a specific tool right so it's not going to be up to this tool to parse through you know a blacklist for a certain tool that might be running it right that tool is already going to know how to do it right so i don't think that's um something that's going to be uh something that you'll have to worry about implementing yourselves okay so so i'm going to turn to the class does anybody have any questions uh follow-up questions for the input concern before we move on if you do have a question uh what we asked is if you could unmute yourself and just state your name um so that everybody knows that uh you're speaking and then uh again you go ahead and ask the question does anybody have any questions about input concern okay so i have a one follow question uh for damien alexis so you guys were talking about input validation for question number three so see uh the system itself is not responsible in doing any types of error checking for example an ip address it has a specific format you don't want the system to pre-scan it and make sure that the format again the content will be parsed by the individual tool that is integrated with the system but as far as some simple input validation you guys don't want it at all right so i'd say it'd be um definitely nice if it could um but i think for us the most important thing is that the tool can give us that immediate feedback in case it's not right so for example if you pass something you know wrong into you know nmap nmap will give you an error message telling you what's wrong so we definitely want that but you know if it can pre-scan it and you know determine beforehand you know that'd be great but most importantly we want that you know immediate feedback so that way you know even if we have to go in and debug it ourselves okay cool um let's go ahead and start the second concern um output uh it would be uh stephen [Applause] hello i'm stephen i have we have the questions for the output i'll start with the first one how should the sca handle the output streams when running the personalized [Applause] scripts i guess um what we would want is um you know some of these tools the output you know as the tool is running live you know so definitely we want it to be outputting you know what it if we were to run the tool from the command line itself you know we'd be seeing certain things depending on the tool that's running um and we would definitely want this tool to give us that same view right not do anything special to it but give us the same thing that the tool would give us and as far as like outputting you know we we definitely want as much saved as possible everything output you know any results that are found as possible that way we can you know put it into another tool that we have for collecting logs and files and that way we can analyze it so the more we collect the more you know this tool can output and save the better for us you know we can sort through it later um we don't want to miss anything so the most we can output i think the better that's especially like error logs um and definitely whenever you have like output of a tool we want to definitely make sure that we log in and keep a record of what command line arguments were entered with that tool right so i have this you know log that output you know this file and i want to be able to know the command that was executed that produced that yeah and in regards to the the personalized script i think it would also depend on whatever the the script is outputting itself so if you know it's a script that's giving you feedback on you know whatever tool is running or or printing statements out logging that should also be included in the output okay thank you i think that would work um i'm going to move on to the next question the what procedure should should be follow for new reports when should the se overwrite or append information to an existing report i'm not sure damian what do you think um i'm not sure about overwriting or maybe you know it's right on the analyst to kind of sort through each scan it does i don't know what are you thinking yeah i don't think we ever want to delete or overwrite anything um i think by default what we would want to do is just definitely append everything together um and then you know if something needs to be deleted like you know we can tell later on if you know the same thing is added later on and we can make that uh call and determine determine whether or not something was overwritten i think just um append for now okay i'm gonna move on to the next question what is the system in place used by the d8 the dac to measure the level of success of the [Applause] execution [Applause] um the execution of of what the whole phase the whole process that we go and [Applause] do what's the level of success that the tool executed said again i think you cut off on my part sorry so is this in terms of the tool so whenever we run a scan what's the level of success for the tool to be successful like successfully executed i believe that would be one of the examples just i mean i'm thinking uh just you know it completing successful scans and if there are any errors giving feedback right so um what do you think damien yeah i mean i think the success of the tool you know yeah it means that um you know things were able to run successfully um the analyst was able to you know if something errored out you know the analyst was able to debug it or make the call and say you know what actually because of the situation with this one machine or something or this network this one isn't going to work actually and then they can make that call i think the success is based on what they're able to do um and output and if they're not able to output it you know it's based on the analyst's decision to say actually you know what i don't want to do this or run this um so i guess just carry out their job enumerating and performing the analysis with it that's what the tool should do right facilitate it and it should just expedite you know our um process as we you know go to these networks and do enumeration and do scans and look for vulnerabilities we definitely just wanted to streamline and make it uh quicker and like vince was saying you know provide a standard for us so that we you know like let's say i you know as an analyst you know i might go in i might like certain tools and someone else might go but they might not want to run the same tools but it could be a value right so now this tool can provide that standard so that way we all run the same tools when we see certain things okay oh the next question is the um the rdd mentioned the output file specification of nmap and nessus what if any are the output file specifications for other tools listed in the rdd and i think you might have mentioned this a little bit already before yeah so so usually every tool will have specific ways to output certain things so for example nmap you know you specify how you want the output and i think that would just be tied you know back to the standardized input file right so a lot of these tools they take that in as an argument you know how we want to output it the file name that we want to give it you know after it completes it's you know after running um successfully i think that would just kind of go back to the standardized input okay [Applause] the next question would be what if any are the requirements for backing up output files output files i mean i don't know about backing up uh if the tool will be storing the files um instead of just exporting them to a actual directory um path to the system that it's running on uh yeah i i'd agree with the lexus um it would probably just output everything into a certain directory maybe um maybe it could be time stamped right so that way you know maybe in the file name or in the directory where it stores it you know there's a timestamp of when that scan or when you know that set of tools was executed and i think it'd be nice if the um if the tool at the end right after running everything if they could package everything up into like a zip or a tar archive but that's i think that'd be as far as we you know go with that [Applause] okay now go to the next question i think you kind of answered a little bit of it um how will the sc place exported files in a specific directory path uh where with the exported files be located in yeah i think that'd be um pry in a configuration for the tool itself um definitely where we wanna maybe it could be part of that standardized input file you know maybe like a global output directory on where we want to save everything we would definitely want to be able to have the option to configure where that is but there will be a default location and that will probably always stay but having the option to change it for whatever reason would be nice okay next question would be since the output since the exported files have a fixed directory path and separate folders per tool what should the se e uh the sea do if there are files in those directories already um i don't think you'll ever have a case where it would want to overwrite the you don't want to overwrite like i was saying we want to keep as many um i don't a lot of the ways that um so this goes to you know how saying that every tool can output um in a specific way and that would be defined in the standardized input file i think that would kind of solve that issue right so i don't think we would ever have the case where we would be outputting the same file name and have like a conflict with file name or anything like that but if we did you know we would definitely want to resolve that and um maybe append something else to the file name to change it so that way it's unique all the time um it's okay if the directory isn't empty it doesn't have to be empty when the tool runs um but i think it definitely should handle uh conflicts that might occur with file names but again this goes also to the immediate feedback you know we definitely want to know that we want to know if you know there is an error and you know what it renamed the file to if it did do that and going back with what demon said earlier also with doing the timestamp um under the names that should also help and solve you know naming issues if you append the timestamp into the naming convention of the files should help okay next question would be uh what information should be included in the statistical report in addition to statistical data mentioned in the rdd what if any are the format constraints to of the statistical report [Applause] other than those mentioned in the rdd oh perfect i think vince would be the one to uh could help answer that question uh as far as the final report so maybe you should repeat that question uh vince i think you would be better suited to handle this question yeah let me repeat it one more time uh what information should be included in the statistical report in addition to statistical data mentioned in the rtd what if any are the format constraints of the statistical report statistical report so that's pretty much like um so like we'll use the tool we open it and we can see like so so the tool the underlying tools we're using will give us some statistical data it's just pretty much showing that whatever that whatever that is so like nasus will show you like uh percentages of low medium and high of vulnerabilities that it found within a specific uh host like stuff like that so so we want to show that within our tool does that make sense yes pretty much like export that data in that tool uh export it but show it yeah so there'll be some sort of api that that these underlying tools expose to like like so people that are programmers can create a program around their tool so you'll use that api to grab that data that it's generating and then you'll you'll take that data and show it in you know inside of the gui okay next question that i have is a rdd mentioned high to critical findings an example of relevant high level level statistics what counts as high critical findings where the threshold thresholds for critical findings and less important findings so that's that again goes to like whatever the tools it thinks is high so it's not like you're going to be coding like uh or having to go look up on some you know national database or somewhere else like is this high or not or you know well i think this one's high like no no like the two the two will figure all that out for you okay does anybody have any questions uh follow-up questions for output concerned jennifer go ahead hi good morning everybody so uh mr vincent for that last question that you answered um for the hiring critical findings so um the stig viewer has like xml files right there you can actually um look and see what the dod references as low high critical rate high impact stuff like that would you want our output to kind of go against that because it's a pretty simple task because they already have an xml file uh well what is it what are you referencing the stick viewer for like sticks for operating system scans cisco switch scans if you can tie it to that yeah that'd be that would that would be something that would be valuable okay yeah i'm sorry go ahead any kind of more information as to uh criticality of a vulnerability would be you know would be obviously be valuable we currently don't do that okay you guys don't use digs [Applause] so just to elaborate um on what vince was saying so like ness is whenever you do a vulnerability scan um let's say um on a system and it has firefox on it and you find like here i have one pulled up a high vulnerability on a mac os would you know be um like security update or let's say a security update for microsoft office uh from july 17th that the nessus itself declares that as a high vulnerability so nessus has um you know a database of vulnerabilities that they found that they themselves um you know classify as you know this is not as bad so i guess what vince was saying is depending on whatever tool and whatever however they define their vulnerabilities so it's not it's not something you guys are going to have to do like you said tie that in like vin said it would be cool but then again um the two it just depends on the tool you're using okay so i'm assuming optional yeah that would be like i said that's a functionality that would be awesome to have but right now currently what we're focusing on is taking our current process and automating that right having a tool to to automate it versus like we all do it our own way you know good thank you so much guys there was another question on the i think someone else jose go ahead uh hello uh i'm from team three with uh the street bottom and i had a question in response to question six about handling the output streams uh desired tool do we want to support um piping into other programs from one command to another so that's all i think that's kind of implementation specific right so if you're going to be using a pipe in your code a little bit in the design phase do you know what i mean so like if you like pretty much what we want is you take the data from these underlying you know uh underlying command line tools and taking that and putting it into the tool that you're gonna create if you use it or stuff like that like sure you know that's implementation specific yeah thank you does anybody else have any questions for output concerned so i have a follow-up question uh for the team so you guys mentioned about the ability to run multiple scans and you guys also mentioned about the output as a report which contains all the results and they're all going to be timestamped so if i have multiple scans running at the same time so when we write the results from each tool would it be going to a separate file that will be eventually merged together or is it one report um anytime there's a feedback from a particular tool you just append to that report i i'm seeing it more so not necessarily in a like uh excel document or in a word document but more so in a data base or something like that so you're just collecting them all so so like you so you run it right so i'm thinking about it like in terms of when you run it so like you you do a run and it'll run all the all of the it'll automate the nmap scans nested scans all these other types of scans and so that'll all be grouped together within that run that you first kicked off and as the results come in that's when you start you know you're building that collection of whatever those tools are reporting back to you cool um thank you so let's go ahead and move on to the next concern which is logging logging it's from lester hi good morning can you hear me well okay so for the next concern i'm going to talk about logging um this first question is kind of a compound question so i'm going to ask it up maybe part by part but what information should be used in the running live log in error log what information like uh so pretty much all those error logs you're going to get information from what the underlying tool that you used so if it breaks or something went wrong with it you'll take that and just that that's what you'll log okay and then following that what logging level should be used well i think that would probably be uh a part of the arguments like we're talking about the going to the that you start off with before you perform the scan because a lot of these tools like i know map does that you you can pass in a switch to tell it how verbose it should be so pretty much telling it how much uh output it should be giving you so it like what it's doing like uh nmap can be very noisy and and be very like it it's always spitting out all this data about every little thing that it's doing or you can say like i don't want it i don't care about all that i just care about the results at the very end right and all those are arguments that you would give it before you kicked off the scan yeah and uh to add on to that i mean every tool there's not like one standard flag or switch for all these tools you know every tool has its own different parameter uh to specify whether you want it verbose or not and then how to what level of verbose you know yeah it's gonna spit it out so yeah that would definitely go back to the um the arguments and the standardized input file okay and then kind of finishing off that first question when multiple tools are running at the same time what are the concerns for constellating them into one live lot so yeah you you would keep all of the that log data you would want to group it together right it's the same thing with the the results that you know like so i kick off of a scan in the tool and it's really running all these other scans right it's really running nmap and nikto and all this other stuff right nasa's but you're grouping all that based off of that one initial c tool scan you kicked off it's the same thing with the logging you all those logs are going to be tied to that scan that you kicked off initially does that make sense you know of course they all have time stamps and all that and you'd probably want to separate out you know this log belongs to this tool or it was created from this tool versus like there's just a big huge flat file and there's a bunch of data and all these logs and i don't know what goes to you know did was this caused by nmap i can't tell okay thank you so for the next question how should information be categorized in the logs uh for example an important vulnerable critical in terms of logs like logging on you know it's whatever came out of the tool right so like uh i would say if it's an error you'd probably want to make that you know higher priority or like somehow show that like look this is an error versus like it's just informational it's just nmap you know waiting on some udp scan to its results to come back versus like oh my broke it's you know it's dead it crashed okay sounds good and then for next question um what information should be logged for each user so there's not necessarily users that this tool won't have like well i logged in as me vince and then you know damian logs in his damien like when we so maybe this would help so what we the way we work is we all get a drive a hard drive when we go on an event and this hard drive has a version of cali on it that we uh customized kali is an operating system a hacker operating system and we have root privileges to that kali instance on that hard drive so we all log in as root right but i'll i'll never usually i would never you know we have one computer and sometimes i log in and sometimes damien logs in and sometimes alexis logs in like no no they'll have their own do you know what i mean so like that user uh any aspect of keeping track of users like you don't have that that's not you don't have to worry about that okay uh for the next question um where and how would the love the log files be saved in a database and maybe it could be an export but for sure i would say keep it keep all the data in the database don't don't do like flat files or holding data in a huge text file or some weird excel document or something like that like no no keep it on a database right okay and for the final question in terms of logging um in the requirements document it mentioned an error log must pop up for the analyst to read and debug when should the error message pop up well when whenever you get it well you know like like don't don't probably you want to put in a log that'd be fine but for sure like okay so i'm running i kick off my scan and right away i'm at breaks right for some weird reason and i don't want to be sitting there thinking like uh did it is this tool working what's going on like you know what i mean i want to know like oh big huge alert error nmap's dead do you know what i mean right or or nmap's running for 20 minutes and then it breaks like as soon as you get any kind of break in any uh any of the underlying tools you're running like show you know report that to the user okay and basically kind of a follow-up question for that is what would the analyst need to do to debug it well pretty so i would say be as show don't don't say like nmap the error has a pop-up in the tool and all it says is nmap is broken you'd probably want to take whatever error map spit out and display that right and then let the analyst figure out like why did that happen was it because my switches some arguments i fed it in were bad did i put a a one instead of an l you know what i mean right okay yeah and the long way you'd know that is like if you just put a generic error saying like you know nmap crashed versus like nmap's reporting like invalid argument dash l or dash one you know that would probably be more useful right the the the error from nmap correct okay so that basically covers my questions um we're gonna move on to if any students have any follow-up or other questions concerning logging jacob go ahead hello um so i actually had a couple of questions the first one related to logging as well as file output would be what format should be used for the timestamps what format uh is that i don't i wouldn't say that i would say a human readable one like uh don't save it as an epoch i was yeah i was more referring to um for example would you have them organized as year month day or similar uh 12 hour versus 24 hour etc uh maybe a 24 hour one and whether you know whether the month or the years in whatever position like it's whichever whichever you'd like and i had one more question as well so you'd mention that whenever an error occurs that we should need immediately notify the analyst should that notification also pause execution for the tool or should the tool continue to run but have the part of it that error just not run well some of the tools will depend on other the output of others right so if you can keep going with some tools i would say keep going but if like if there's a tool relying on the map scan to return then obviously that one won't go right you should pause that one understood thank you jose di uh jesus oh no jose do you have a follow-up question uh no thank you actually i was gonna ask what mr dusseld asked okay cool um if we don't have any more uh follow-up questions let's go ahead and move to uh tools for the next concern it would be jacob hi again um so for tools i guess i'll just start with the very first thing we've got here what kind of dependencies do the tools have and how should c handle them if they're missing what kind of dependencies should the tools have uh what kind of dependencies do the tools have so for example um nmap from what i understand would work right out of the box if you installed it but some other tools might have existing dependencies that need to be installed prior to execution how should the how should c handle it if some of those dependencies are missing so all these tools you know we current like i was remember i was talking about our kali image that we have so currently they all we can run them right like by hand so they wouldn't all of that dependency uh you don't got to worry about the pit so when you build it when you get to the next software too and you do it then you're gonna have to worry about that right but we won't because we our image will uh has all that taken care of that makes sense yeah it's not the tool's responsibility to make sure that those dependencies are met yeah it won't be an issue on runtime for us let me jump in a little bit um uh for question number 20 uh the first part of the question i think the team who came up with is more focusing on if the output of a particular tool can be used as an input of another tool that's the kind of dependent data dependency is what they were referring to oh yeah that that can definitely happen so then that means that some of your tools will have to wait for others to finish so and remember how we were talking about extensibility so part of when i add a new tool would be i would like give me the option to set up that dependency if that makes sense and that is being set up as part of the standardized input file right right thank you all right our next one would be how should c handle prioritization of tools so i guess that's kind of a similar question right like uh so you we want to somehow in our in that configuration file give me an option where i can specify uh the input of you know smb map would be the output of an nmap scan so i can you know like if the nmap scan shows there's no hosts that have smb as a service then i probably wouldn't want to run smb right does that make sense that does make sense um i have a small follow-up to that then would the c program be expected to understand the outputs of programs such as nmap to know if it should run an smb scan absolutely it should like same thing with nicto so nick those for websites right web it's a web vulnerability scanner so if all my machines that i've scanned have no web service web servers that it knows about then i probably wouldn't want to run that right thank you our next question is how should c handle data dependencies between tools i believe you already explained this one um but i'm gonna ask it anyway so let me let me jump in a little bit so if the question has been answered uh uh based off of the presentations early a presentation earlier or through discussion of other questions of the representative please rephrase what you heard from presentation or answers to other interview questions and then our clients could go ahead and validate your answer so from what i understand then for number 22 how should it handle data dependencies between tools c should be capable of knowing which tools to run first and then based on the outputs of those tools and assuming the tools run successfully run follow-up tools that would be dependent on the previous tool's output right okay let me read this one first all right what are some example tasks that the personalized scripts would be able to perform uh like just think it could be just like uh just thinking up an example off the top of my head let's say i built a python script that uses scapy that can send uh customized packets to a particular host or a particular set of hosts and and receive data back like that could be an example of a customized script that i would like to incorporate in the c2 or even just like another kind of a scanner that that we have available to us on our on our cali image and then um as an extension well it's the next question but as an extension of that to allow personalized scripts what type of shell functionality should c support and in what language should the scripts be supported uh anything you can run on this not the command line so python bash scripts you know most of the scripts that i think we have are bash scripts in python so i think starting there would be a good uh good place to start but really anything you can just run off the command show uh that was the last question for this section are there any follow-up questions from other people go ahead and move on to maintainability um so uh jacob uh we're gonna do that in the order uh that we have in the uh interview file so when it comes to the maintainability will uh go back to you oh no no sorry sorry let's see performance uh oh no sorry am i look at the wrong list let me see hang on a second uh the 9 a.m you have okay so we got done with lester uh we have tools um let's go to jennifer user interface and we'll come back to you uh in a later time user interface all right yes ma'am hi to y'all all right so going getting started the question i have to read is what functions or commands of c would be in the gui form considering most of the tools specified in the rdd or terminal based applications right so so the what it spits out just pretty much i'm pretty sure that that it could most of these tools spit out data in a formatted way that you can just kind of show in a gui that you can parse that you can parse and then once you have the little pieces of the data that it did it spit out you can just show on a gui you know table something like that i guess that when you get to the like the gui design aspect then whether it's a table or a field or how however you want to show it you know sweet sounds good honey all right i'm just going to keep going to save on time so uh what do you like and not like about tools and programs that you have used in the past uh [Music] what i don't like is weird mysterious errors or usually most command line tools you know you give it some switches and then you give it a target host at the end sometimes it doesn't work like that and then you're trying to figure out how it wants you to give the the arguments you know so we had something to co to that's why a lot of people don't use all the same tools because they don't they're not familiar with them all right so we had some kind of a layer in between where you can just give it the data you know give it give the c tool the data that you know you want to the arguments that you know this tool needs and not worry about like you know does it go in this order or all that sounds good so i'm going to keep going how should the scanning process be represented in c how should the scanning process represented yeah like do you want like a like a taskbar kind of like how ida has like at the top you know how like you know where exactly in the file you are right okay so like for sure some some sort of feedback so we know what's going on like so if if it hasn't even like the ms scanner isn't even finished and we know that smb map hasn't even begun you know that would be good versus just like you know i don't it's just looking at you know it's like a little spinner just spinning spinning spinning you're like what is it done is it almost because it end map could take forever that's good so you want to know like where in the process it is at what given time so you know which tools have rung which having what you currently have in the form of the process yes and sometimes actually give you like how long it is okay great sounds good um how should output be presented in c tabs external windows or default text there how that was supposed to be yeah so how do you want the output to be represented and see like tabs uh external windows you know so external window searches are not a good idea having pop-up windows and all that not a good idea having uh actually we were discussing this the other day with my with the team um i like have seen as much data on a window as possible that makes sense like having everything on there if it's overwhelming is not a good idea but if you break it down into too small of units and you got to click around too much it's the clicking around that's that's uh that gets cut you know tedious where like you know you forget like what was that other value and you click here and you're like uh wait a minute what was it again and then you got to keep clicking back you know it's like so you want to reduce those kinds of those kinds of cumbersome actions that a user takes you know so like things like you know too many tabs two too small of data units pop-up windows all those are like not good ideas i think that's good i concur so that's the last of the questions i have so i'll ask for any follow-ups okay no follow-ups let's go ahead and move to uh team six uh user hello can you hear me all right uh so for user we have three questions uh i feel like the first two were kind of uh touched upon but i'll say them either way uh the first one was what technical background will the end user have and i think that kind of speaks to what you were talking about of how you present it um and and the xml file and all that and then the other one was uh what are the differences between analysts at dac and again i feel like you touched on that with how the scanning process works and uh how it's like the bullseye analogy and uh how the different uh people kind of attacked uh that process so i'm gonna touch on the third question which is how should c handle uh multiple analysts working on the same machine at different times i know you mentioned that you guys work with a hard drive and you guys have root uh capacity but uh how should c handle uh the multiple analyst uh working on the same machine at different times so that you don't got to worry about that you don't got to worry about users or logins just like you know just build it as if you click on it and and there it is ready to go it doesn't log in and it doesn't like well vince is using it so i'm gonna all these actions are gonna be tight to him like no no just since we do have our own hard drive we don't share we usually don't share machines okay uh so just to follow up on that since we're not worrying about that uh c is kind of a program that will be handled like that hard drive for everyone to use uh personally correct okay uh so in terms of user uh that i don't know if anyone has any follow-ups because uh i feel like the first two were covered extensively does anybody have any follow-up question for user i have one question not directly tied to user but in a sense it is so you guys mentioned about the different hard drives and each hard drive would have a database collecting all the results all the logging that was being run by the owner of the hard drive there's no need to merge the data sets uh let's say vince you have a hard drive alexis you have another hard drive and daemon you have another hard drive after you perform uh after you've gone on the event you guys don't need to consolidate any data send it to a centralized database or anything right no so the way our process would work is uh [Music] you use the tool you get all the scanning data so like let's say me alexis and damian are on an event and we have a huge network to to test uh we would break you know like i would get a certain subnet or a certain set of ips they even get another one alexis we get another one and then we do our scans so we're not scanning the same exact toasts we we split it among amongst us and then based off of those scans i get a certain set of you know vulnerabilities that found or a certain set of hosts and services that i can see and everybody has a different one so we mentioned that export feature that would export into another tool that we have so once we export into that other tool then that other tool actually can do merges and stuff like that so that's so so any of the merging stuff we don't really need to worry about for this one okay cool let's go ahead and move on to extensibility okay uh so so that's me again uh so when a new tool is added to c how should c handle uh a configuration settings uh b path name and uh c arguments so path should be static right like uh because all it's doing is running something that's on the underlying os right and so usually programs are on cali or in uh where in etsy at sea var or etsy tools or wherever they're at right so that'd be a static thing uh and arguments are all very tool dependent right but pretty much if you can run it on the command line you know you can give it a list of arguments does that make sense yeah and then for uh configuration settings so configuration i would imagine would be similar to just the arguments that you're passing in okay that's that that that at least was in the slides was what i meant by configuration uh other other types of configuration could be like uh remember how we were talking about how some tools are dependent on others on the output of other so that would be another piece of configuration data that you would probably need to take into consideration okay and then uh the last question for extensibility would be what protocols are in place determine the security and reliability of a potentially new tool being added to the system so you're asking whether the c tool has to worry about secure security of the tools that are being added yeah so say we wanted to add in a new tool to see uh how or what should uh what a protocol should c already have in place uh to determine uh the reliability and security of this new tool that may be added so you don't got to worry about that we have a pretty rigorous uh process to just get stuff on that custom image we have okay so if it's on there you know it's good to use like see shouldn't have to worry about is this a malicious script or is this thing gonna do something bad you know what i mean so pretty much it's it's already gone through uh the process you guys have and what it's getting to see it's already gone through uh like you said that rigorous process and it's something we don't have to take into account correct okay i don't know if anyone has any other follow-ups but that's it for extensibility okay so because of time let's go ahead and jump to parallelism uh jennifer sweet hi again all right parallelism the rdd mentions thread management monitoring and termination please elaborate on the definition of thread so threat i don't know if you guys took operating systems yet it's just you know uh so a process you can run things uh simultaneously sometimes code simultaneously that's what we mean by thread so like if you can run let's say map's done you can run crap map crack map exec and enum for limit linux at the same time then let's do that you know like to save time right great i gotcha and given we're short on time i'm going to rush through the second one what is the maximum number of threads that can be run concurrently um let's just say you know for requirements sake let's say 20. run as many as you can and like fill up your your memory yeah and slow everything down but it's just like we'll cap it at 20 let's just say that all right sounds good and then what is the maximum number of scans that can be run concurrently by scans what do you mean like like me kicking off the tool or you mean like an nmap scan or another tool scanner yeah i'm gonna say that the person who made this question is talking about like the complete scan of the c tool i would say just one at a time yeah sounds good and then how should c support simultaneous the assignment simultaneous data analysis right simultaneous data analysis yeah well i guess uh if you can make it multi-threaded in in terms of it determining something or analyzing something and not having not having to wait or depend on other pieces of data from other scans then okay i'm that's cool with it being simultaneous but really what i meant by some like thread management and running things in parallel was mostly running the two underlying tools in parallel not necessarily processing the data that comes back in parallel if you can do that yeah that's great right make the tool faster but really what we meant by that in the rdd was running the underlying tools concurrently if possible right um miss elsa i have a follow-up question based on some of these may i ask okay hi so you know because we're talking about threads and then you know blend up memory is there something you want us to do in case like we're thrashing you like a like a like a complete you know just exit out to completely stop it because if you're thrashing it and i'm assuming your image is in the virtual box for vm right you don't wanna that already takes up so much memory and then especially if you're running like a browser because firefox and chrome is gonna kill it so what if for what if this tool causes with us trying to like run all the threads concurrently and all that stuff what happens if we're like over thrashing and it's like killing everything because you want like a kill switch or something yeah like something stop everything would be nice we don't really run stuff in pms we run it native so you don't have to worry about too much about uh resource you know because since we're not in a vm we're running natively we have more resource but yeah we want to like just absolutely stop everything because we gave it some crazy uh arguments to all the all of the all of the underlying tools that we're gonna run and it's taking forever and it's been running for two hours and i can't even open my browser and they're asking me to go do something specific and i can't because this tools locked my computer up uh yeah that'd be good stop everything stop everything totally do we know what type of hardware you're going to be running it on uh yeah i don't know i don't know i'm supposed to if i'm supposed to tell you guys that it's okay you know there's no room in asking okay all right thank you so that is it for parallelism if anybody else has any follow-up questions so um thank you so much for coming to class today and uh thank you our clients to uh agreeing participating in the interview so that we could learn about uh more about the project and answer some of the questions you guys might have so uh what we're gonna do for the all the unanswered questions um hopefully we'll get to it in the second uh interview that we're gonna do at 10 30. uh please pay attention to the audio file that i'll be sharing for it uh from 10 30 and if any of those questions aren't being answered i'll work with the clients and give you guys a memo at a later time okay thanks everybody um i will see you guys in class on tuesday bye everybody
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
from our uh clients team uh would you guys like to uh talk a little bit about who you are what you do uh in your organization before we get into the interview part uh sure my name is vince von seka i've worked here at cc dc dac for three years and uh my title is computer scientist we kind of do a bunch of kind of a jack of all trades but one thing we do that i've been doing is pen testing penetration testing i'll go over over that a little bit more yeah hi everybody my name is damian i'm also technically a computer scientist but also just do a lot of penetration testing i've been with ccdc dnac for almost two years now i got my bachelor's of science in computer science from utep in 2016 and my master's in software engineering in 2018. hi everybody i'm alexis i just graduated actually in may with my master's in software engineering from utep and also my bachelor's of computer science from utep so i've been in your shoes um yeah i've been i just got hired from ccdc dac it's an amazing place to work and yeah just like damien and vincent said we do tool development penetration testing all that good stuff well thanks for introducing yourself vince you want to go ahead and get started with the presentation sure okay so uh we're from the us army combat capabilities development command data and analysis center so that's our the full name of our organization uh and pretty much we do pen testing so uh i'm not gonna go over like the owasp pen you know steps of penetration testing these are more steps that uh that i've noticed that we do when we go on a on a particular event so what i'm calling an event is pretty much uh that there are various organizations in the in the army and they you know they create networks vehicles devices all kinds of things that that they want to test and so they'll hire us to go and pin it you know perform a pen test on on their uh project on their whatever it is a car maybe and that's what i'm calling an event so pretty much we have four phases in our penetration testing methodology a planning phase uh which is pretty much planning what we're gonna do and how we're gonna test the system what the system even is and then once we get on site we actually we the first step is to perform the discovery phase so we're going out and seeing what you know if it's a network what hosts are on the network what services are running on each host what vulnerabilities are do any of these hosts have that are associated to any of those services and then once we uh can come up with a list of vulnerabilities and we try to actually exploit those vulnerabilities that's the attack phase so we'll try to perform uh uh exploits on those vulnerabilities if we and if we successfully exploit any of them we we uh re write you know we record those because we're gonna like when we get to the reporting phase we're gonna have to create a report as well as a as well as a presentation to the customer showing them all the stuff that we found so here's going into it a little bit more in depth uh the planning phase is pretty much we meet with project manager stakeholders to agree on vectors to test now a vector is uh so let's say it's a it's a network that each node communicates to each other node using a specific customized protocol and the the project manager wants to make sure that that customized protocol that they created is is you know is they want to know whether it's vulnerable to to a malicious attacker or not so that would be one vector that we would decide on that we're going to test and so like you know as we're meeting there they come up with a list of vectors that they want to test for their specific system and so when they tell us you know they'll tell us all those will agree on all these vectors and then we create a test plan and the test plan is pretty much uh where we agree on okay so the first day we get there we're gonna just do pure scanning and enumerating and then the second day we you know we're going to start working on you know this particular vector and then you know the third day on another vector and so on and then you know uh at the la the last usually our test lasts between a week to two weeks and then like maybe the last day we'll have a little quick uh a little quick presentation showing them high level results of what we found and then of course in the planning phase we have to like procure all our hardware and software you know get all the people that we're gonna send depending on how large the system is uh get computers for everybody if we need customized software get that software on our on our machines before we go uh pretty much getting access to the you know if it's a special uh facility getting access uh all all of that stuff and then once we're there then then we can start the first step in our penetration test is to scan and enumerate so scanning is pretty much just looking to seeing what's out there and uh recording all of them uh all of the hosts that we find as well as the services that each host uh has exposed to the network right and we we use various scanning tools to get a list of of these hosts and services and we also have vulnerability scanners to see if any of these uh services on any particular host is vulnerable to you know any kind of specific exploit and these are we're using like uh mostly free tools some of them we do pay for to perform scanning and to perform the vulnerability the vulnerability scan and then once we get a nice list of all of the vulnerabilities all the hosts all the services then we have we like to make like a visual map including our attacker machines included in the map to so we can get a nice little good layout of the way the network looks what's vulnerable what's not what's been tested what hasn't been you know that's so we use that map when we're as we go forward in the test and then the attack phase is you know all that data we took from the discovery phase we're going to now actually try and exploit all these vulnerabilities we find and if we do if we're successful in exploiting a vulnerability we have to document that so we have like a team of four people you know i i don't find or three people i don't find any let's say damien finds four he's gonna have to record all those four that he found you know taking screenshots writing down the steps that he took maybe even like a mitigation like what you know what the customer can do what the project manager can do to uh avoid to avoid this exploit maybe he would know that at the time and then of course like the last thing we would do in the attack phase is if we left any uh hacker stuff on any of these systems we gotta remove it especially if the system is an actual production system like it's really being used it's not in a test environment it's in the real environment and then finally you know we do we give we give in the reporting phase we give what we call an emerging results brief and that's usually on site that was that uh a presentation i was talking about at the last day where we give a high level uh presentation on all of the exploits that we found and then once we then we then we can come back to here at white sands missile range take all of these exploits all the data that we found and actually do an in-depth look at all that and find out what is the impact of each of these exploits to the customer to their to their network or whatever it is and then we create documents uh that that explain this impact to them like if you don't fix this you know it could be really bad like you're you're putting a war fighter in danger if if you don't fix this vulnerability and also like showing them like this is how this is how you would fix it you'd upgrade your software or you would you know create a firewall rule so none of this bad guy traffic can get into your network so that's pretty much a high level of our testing our penetration testing methodology so the problem that we have is in the scanning and enumeration phase it isn't consistent so so kind of like you can see there with the the bullseye and the arrow you know not everybody some people are better at it than others some people get closer to the bull's-eye than others and this is probably because uh well this is because not all analysts are familiar with all the tools that we have available so some tools that we all we all use we all use nmap and we all use what we call nessus which is a vulnerability scanner but there's other tools like say you find a particular you find a set of let's say windows machines that are running smb like not a lot of people know to use smb map to go see if you know what what uh what vulnerabilities exist on those particular windows machines so like that's what we're trying to do is we're trying to get all all of so every every analyst when they go when they're performing this scanning and enumeration phase will perform the exact same steps instead of just like well since i'm familiar with this tool i'll run it whereas you know like maybe i'm not so familiar with it so i wouldn't even know to run i didn't even know it existed right so that this is the need that we have so a little bit more about the discovery phase running scanning enumeration and enumeration tools to get a list of hosts and services we we mostly when so nmap is a tool that stands for network mapper it's a tool used to layout to to figure out the you know what hosts are on a network what services are running on each host and and so forth so and nmap is a pretty large powerful tool and there's like a whole bunch of different arguments that it can take but for the most part we all use the same arguments into the tool that's what i'm calling switches and so it'd be nice if we had a tool that could you know have an easy way to for a user to give it different kinds of arguments [Music] and you know we would like to make that's and all these other tools too have like different arguments that it takes and so we'd like to make this easier to configure all these tools right and also have a nice set of tools that we're going to use that we know work well versus like well i know this one works well but nobody else knows it so i'm the only one that's actually using it and then running vulnerability scanners to see what vulnerabilities this is the vulnerability scanner part like we usually use nessus and whatever that kit gives us uh we'll we'll use that data but then sometimes like we we have access to nicto nicto is another tool of vulnerability scanner but specifically for for websites and not everybody uses nicto but maybe you know some maybe nicto might find something that nessus didn't find so you know that that's why we'd kind of like to standardize all of these tools whether and obviously if there's no web uh web server on the network then we don't want to run nikto but if there is then we we would like to and hopefully that could like find another extra vulnerability that maybe nessus didn't find okay so what we need so what we're calling the c tool the scanning and enumeration automation tool this is what what we would like to help standardize our scanning enumeration process so pretty much what we want to see tool to do is accept a white list of ip so whitelist is let's say on a network the the ips that are in play that we actually want to go look at and and and also a black list and the blacklist is obviously like do not touch those ips uh no matter what so this is important like saying a production system where they say okay these are these specific hosts we want to see these are the ones we want to test but these other hosts do not touch them do not scan them do not do anything to them no matter what so those are two pieces of data that we want the c tool to take in and finally like the tool arguments like i was telling you how nmap we just pretty much give a map the same set of arguments we would like the tool uh to take in like you know different arguments to each of the specific tools that it's you know that are running that it's running in it on underlyingly run right so here's an example so once it takes in those um those arguments those three pieces of data like it then this example shows it running nmap on a particular network so taking those arguments to nmap it'll go and actually perform the nmap scan on the white list of ips you gave it and then it'll get those results back and save them and so i have listed here some other tools besides nmap and nessus is we would like to run durb go buster which is pretty much so if there is a web server out there durb will go and pretty much brute force all the url and see what other kinds of uh web pages or com you know administration pages is does that server have available have exposed to the network uh cutie cap is pretty much uh that's a tool that similar to durb but what it'll do is it'll take screenshots of any web pages that it finds sometimes this is useful you know like we'd want to take a screenshot to show the user like look you you have like some kind of data leak available here all i got to do is hit this website url and it'll show me like you know let's say uh the particular version of apache server you're running and maybe they might not want to expose that uh nicto like i said is like another vulnerability scanner smb map pretty much can show you vulnerabilities if the smb service is on a particular host enum for linux will find a whole bunch of uh a whole bunch of data that that like let's say a windows host has that that that's built for windows and crap crack map exec is pretty much trying to gain a foothold access to a windows machine uh through the services that it exposes so not everybody uses those not all of us analysts use those but if we had a way to a tool that standardized all that that's that's what we'd like and then finally we'd want uh our tool to kick out uh so okay it did the scan has all the data and then we'd like to that data to be exported into an xml format that that we specify because we have another tool that can actually map out visually the network if it's a network map out the network and all of the services and any vulnerabilities that it found on you know on those particular hosts so we'd like to kick that on to an xml file that will ingest into another tool that we have and some other properties we'd like this software to have is to be extensible so if we wanted to add let's say a customized python script we will be able to do that easily through through some gui without having to change the code or another underlying scanner tool that we that we have available we would like to be able you know be able to add that easily uh we'd like the tool to run in parallel when possible so if i can run crack map exec and enum for linux at the same time you know to save on time because sometimes these uh scans take these uh vulnerability scanners take a while we'd like to run them simultaneously and and we would like it to uh maintain proper logging so like uh maintain what all of these all of the output that these tools if it's informational or if it errored out or even when it ran you know like we want to keep a log of all of that stuff and i think that's that's it okay uh questions so we'll go ahead and get started or each teacher if the question has been answered by our clients in the presentation itself or while answering all the questions um i am asking you to paraphrase uh summarize what you have heard and then uh and then have the clients validate your um answer instead of having the uh clients repeat uh the answer okay so let's go ahead and get started with uh the first concern which is input um so we have a total of ten teams uh we have just representing team seven um jaime representing team eight kevin representing team nine adrian representing team ten uh abram uh representing team 11 eric representing team 12 uh cesar representing team 13 alejandro uh representing uh team 14 uh jacob uh team 15 and gilbert team 16. let's go ahead and get started with the input uh concerned jesus um testing one two can you hear me um so the first question uh what is standardize what is a standardized input file a standardized input file would be uh like an xml file that you define or somebody defines and these are the you know this is this is where the white list goes the all the ips go here all right and all you know the blacklist ips go here and the arguments to map go here like that's what we mean by okay standardized um so the next question uh the rdd mentioned some tools uh might require either a whitelist or blacklist of ip addresses as inputs what about the inputs to the other tools well that that would be the the argument list right that the third piece of data okay list um so next question would be uh input validation refers to checking whether an input would be accepted by a certain tool what if any are the conditions when input validation is not enforced when it's not enforced uh i don't think there's any kind of freeform data right so you probably probably would in terms of input into the system i don't think there would be uh where you wouldn't where you wouldn't want to have some kind of uh checking you what know would you like for the automation process besides the input needed to run the vtools for example choosing which tools to use and setting the number of threads to run in parallel uh so say it again sorry i didn't quite understand uh what options would you like for the automation process besides the input needed to run the tools for example uh choosing which tool to use and setting the number of threads to run like in parallel yeah i guess that would be a good uh option like let's say i only want to do nmap and nothing else or i i only want so many threads to run concurrently because i got something else running on my machine and i don't want my machine to totally freeze up okay last question for me would be um so the rdd mentioned the commands and ip address list would be given through a standardized list please elaborate how you would like this function to work different tools a set of different types of files for example nmap uses a dot nsc file that might call different tools at the same time what if any are specific preferences for the standardized file uh well in terms of nfc files like you'd have to have that first of all on your box right and i see that just as an argument like like any other like any of the switches or any of that so real really all i see is like uh input into the tool would be arguments to the underlying tools the white and blacklist and maybe stuff like we're don't run this tool run this tool have this many threads uh she's uh wait you know i get i guess the toolshe also know that some of these other tools are dependent on on like let's say end map so if you want to run smb map first of all you gotta have to know that smb service is running on a particular host and you and the only way you'd know that is if you ran nmap right so like some some of the these tools is output will be used you know for input into other tools does that make sense but i don't know if that would quite be uh input that a user gives it it should just know that you know it should know to do that so i'm going to open up to the class does anybody uh in the class has any questions about inputs if you have a question if you could raise your hand then we'll call on your name uh cesar go ahead uh hello um so i'm just curious so you also want us to implement new tools and uh some of the tools use the output of other tools as input um how would we know how to do that for a new tool for example so some of the tools that well depends what you mean by new if you mean like just another tool that's available in the cali operating system that's to me you would know right so you would know what this tool already does but like let's say i created a python script that doesn't really rely on on any uh other on anything you know but so all of this dependency you would know beforehand i guess is what i'm saying okay thank you so i have two follow-up questions um based on what was being discussed the first one is about input validation so vince you mentioned about input validation should be enforced at all times could you elaborate a little bit more of what we what you guys meant by input validation is it checking um on a specific format for some of the commands uh or the listing whitelist blacklist that's where structure goes um in the standardized input file yeah so like maybe uh well for sure for the white and black list if it doesn't look like an ip or it you know it has a.a.a.a or something weird like that obviously you know you could you could validate those types of things uh for like say um arguments to the other tools i'm pretty sure they're not going to take uh weird characters or i don't know it's kind of hard to to to tell what what new tool you know what what it won't or will have right so in a nutshell it's um the students should be doing some research on the different tools that you guys have listed kind of get a feel of what are the commands um to come up with uh some sort of rules and then during the semester they could present it to you guys and then we could consolidate what kind of uh input validation rules that we're referring to yeah that could work like like you you would know beforehand all the switches that end map takes so you could definitely validate the nmap stuff but like say a customized script that i built that only i you know i know the the switches that it takes or whatever they might change as i make changes to the tool yeah well you know maybe you wouldn't know those so easily so is there a need to have a like a configuration file so to speak um for the user to define hey for this new tool this new script uh that is going to be a new underlying tool in the system uh do we need to define some sort of uh again quote unquote input validation rule in there so that when the system is taking the standardized input it would know to run not only the standard uh input validation rules but the new rules that we put in yeah so all these rules would be specific to each tool right yeah so maybe that this c tool there's somewhere where i can say okay validate it against these particular arguments and if it doesn't have them then throw a warning okay um another follow-up question is um on the standardized input file so you mentioned there are uh three types of information that were contained in there there's like white list blacklist and two arguments you also mentioned about the concept of configuration file where um tool dependency uh the output of a particular tool will be used as an input uh to another tool and you also mentioned about um the dependencies should be known prior to running so the analyst has this information is that information going to be put in as part of the standardized file is there a difference between standardized input file versus configuration file well i guess you could put all of that data into one file i guess that's possible or break it out into separate files so as far as the tool dependency of one uh the output of one getting fed into another uh as an input of the other one um is something that the analyst could specified on the fly right or is that something that is uh standard for everybody it should be standard like it wouldn't i don't see dependencies necessarily changing unless they said okay i don't want to like let's say uh smb relies on map right and let's say that they're like i don't want to run in map already ran in map and i know that this one host has smb and i want to run this scan again so i only want to run smb so like obviously smb relies on nmap but if i only want to run it you know it should probably take my white list and then my arguments and then run it you know so i guess that that would be something to take into consideration okay so let's go ahead and move on to the second concern output uh that would be jaime hello can you hear me uh okay so to start off with uh our the first question would be how should the c2 handle the output streams when running the personalized scripts so most of these tools underlying tools right will probably have some kind of an api so like you can uh interface with it through a programming language otherwise you're gonna have to like take the raw output that that it kicks out from the command line and somehow make sense of that parse it somehow parse it okay all right uh for our second question what procedures should be followed for new reports when should the seats will overwrite or append information to an existing report so a report will be it won't be like a file that the c tool exports it'll be just like in the gui so like it ran you know i ran crack map exec and now i'm looking at the gui and it's showing me what crack map exact uh what the results were okay what i mean but like some other tools uh you have the option of looking at the output as it's coming in does that make sense so like it shows you the most recent like map does that it it'll show you uh this is where i'm at this is what i found so far i'm not done yet right so probably the gui should reflect that okay uh for a third question what is the system in place used for by the dac to measure the level success of the execution the level of success like whether it broke or not you mean or like success uh if it was able to like scan effectively like this so currently we do all this stuff by hand right like we're we run map by hand we're nekto by hand run nasa's by hand and so pretty much we just got all this data sitting on our computer that it kicked out either we save it in a file or it's sitting in a terminal pretty much and we're just going off like that you know like so if we had all this data centralized somewhere so even though i you know to i close my terminal it's not gone it's saved somewhere you know what i mean okay so that's kind of where we're wanting to go to so in terms of success or not i don't know it's hard to it's hard to say like what we're trying to do is automate our process and keep track of what we've done versus like oh i remember nmap returned something interesting but i closed that was yesterday and uh i restarted my machine so now i got to do it over and it took you know 30 minutes and it's in that this is wasting my time and it's night okay uh the rdd mentioned that the output file specification for nmap and messes what if any are the output file specifications for the other tools listed in the redd uh output specifications uh with nicto and all that uh you'd have to go look at the api it's either that or you go take out whatever the it kicks out on the to standard out and then you'll have to capture all that standard out output and somehow parse it okay or just show it straight from whatever you're receiving just show it in the gui okay and i'll obviously keep like save it save the data okay uh what if any are the requirements for backing up output files no i don't think you should have to worry about saving output files you should i think as long as you save the underlying data the underlying result data in a database or somewhere that you can regenerate all of these output files on the fly okay so like you wouldn't want to say like well i created like i ran five scans and each one i had an output file so i have five the system is keeping those five output files in its database somewhere like now just go re-run it right now just go recreate it um how will the c tool place the exported files to a fixed directory path uh where would the exported files be located in so we have a customized so when we go on a test let's say there's three of us right me damien and alexis before we go we each have they give us a drive a hard drive and on that hard drive is a version of cali that we've customized and on that customized version of cali we have in the file system a specific uh folder uh structure so what we're talking about like where where it's gonna kick out that file to a specific folder that that will all be known beforehand does that make sense because we know all of our images have that same folder structure no matter what so we sit we get this so like imagine the c tool works we we have the c tool it's on our machine we stand it up we start it up we do the scans and then we when i press the output to give me the output it knows like oh that file structure already exists so i know where to go you know to which folder to go write the output okay all right um since the exported files have a fixed directory path and separate folders per tool what should ctool do if there are files in those directories already if there's font well uh like so it's either you overwrite or you don't overwrite right i would say you enumerate you start enumerating okay does that make sense so if you have like you know output.xml and then you did it again it's going to be output underscore1.xml you know two three four whatever yeah okay uh what information should be included in the statistical report in addition to the statistical data mentioned in the rdd what if any are the format constraints of the statistical report format constraints so i would say all that statistical stuff would come from whatever the tool gave you okay so you're pretty much just reporting whatever the tool is reporting okay uh our last question the rdd mentioned that hi to critical findings as an example of relevant high statistics uh what counts as high to critical findings and what are the thresholds for critical findings of less important things findings like that so once again the like a vulnerability scanner will tell tell you what's high what's informational what's medium you know so you're not really um the tool isn't smart enough to go like oh i found this uh buffer overflow or this sql injection vulnerability and then it goes and looks up in some database that you gave you know that you created and it goes oh this is high you know what i mean like the the tool will know although in the last class uh you guys could look up what a stig is stig okay and those kind of also have uh rankings in vulnerabilities found so if you did find a vulnerability that maybe a vulnerability scanner already ranked maybe you could bump it up against that as well if you you know but really what we're looking for is currently we don't use that currently we don't do that currently what we're trying to do is just automate our current process okay so does anybody from the class has any questions about outputs okay let's go ahead and move on to the next section which is logging logging will be kevin so what our first question is what information should be logged in the running live log and error log and also what login levels should be used and when multiple tools are running at the same time what are the concerns or consolidating them into one live log so what you'll be logging is mostly what the tool is telling you what what output the tools giving you right maybe you could log like when i press the to kick it off to start and maybe when i uploaded some configuration stuff you could log that sure but most of the log will be uh data coming out of these various tools that you're that you're running but i you do want to keep all of those all of that output uh grouped together like let's say i press the button go and it starts running like five or six different tools and all of them are creating data and logs you'd want to make sure that you collected all those into a set that can be tied back to when i press that the go button does that make sense so if i did it like five times you have five groups of logs and and with the errors like uh you should you should log them yeah sure but you should also show them to the user immediately like don't just save an error in a log in like oh i never told the user and the user sitting there looking like uh what's going on it's not doing anything you know because like some because three of the tools broke crashed okay uh so next question is how should information be categorized in the locks for example unimportant vulnerable critical so that's all like data coming out of the of the tool right so some of the data coming out of the tool is actual useful data and some of it's just informational the tools telling you like this is where i'm at in the process or this is what i'm doing it's not actually like well i scanned this host and this is what i found so there's those two different kinds of data coming out of a tool that i guess you could stick in a log but like if you're like well here's the log the only other way i could see you could like break out logs is like by errors and just data so if it broke you know maybe you could keep that in a separate place somewhere i wouldn't say a full a file this is i would say keep all the data in a database don't like start kicking data out to some weird excel file or some really really huge text file that's heating up all the you know memory somewhere on my machine and rather just eat up the memory on the database that makes sense yes so next question is what information should be locked for each user so the concept of users there won't be any concept of users since so like i think i mentioned before like we all so there's three of us on an event we all get our own hard drive and it has a customized uh image of kali linux on it and we all log in as root so it's not like i log in as vince you know damien logs and his damien likes slugs in his alexis no no we're all logging in as root and as far as the tool knows it just thinks roots running you know root's the one that's running all these tools so i wouldn't say you'd have to worry about users or keeping track of users or any of that or logging into the tool or anything all right uh where would where and how would the log files be saved database okay and the last question concerning login is the rdd mentioned an error log must pop up for the analyst to read and debug when should the error message pop up and what would the analyst need to do to debug it so right there should be as soon as it as soon as the tool knows right and don't don't throw errors that say like well maps map broke like literally that the text map broke like give me whatever error in map reported so i can figure out like this something is my is my instance weird did some did i do something weird did i turn an interface off so it can't see out you know all those things will be in the error message that map gives does that make sense yeah thank you does anybody from the class has any questions about uh [Music] uh logging okay so let's go ahead and move on to the next section which is tools um but somebody have a question yeah i didn't have a question go ahead um i i don't know if this is for output or logging but in regards to i guess it would be logging in regards to maybe if you guys wanted to rerun a scenario so let's say you guys did find a vulnerability and uh you guys wanted to it was like an extreme vulnerability and you guys wanted to explain to the client what happened and you guys wanted to run through the whole scenario again would that fall into logging did you guys want that as a capability to do or is that something that that you guys don't really worry about so that's a good point sometimes we do uh do those things like let's say i found a vulnerability you know and then now i'm trying to document it and i'm like oh man i found it yesterday and i totally restarted my machine and like all you know i want to take screenshots and have all this stuff to prove right or even i do want to show the client like he's sitting right here and i'm like look i can look what i can do but i have to run all those scans all over again like yeah i wouldn't like logging is all logging is going to do is just recording what i guess the initial actions the user took but mostly it's going to be recording what the scans doing you know so like if i can show them like currently like look here's in the c tool here's my log it shows exactly the output of the of nmap or whatever or cracked map exec that could be in a log or i could just literally do it over again and it gets logged again right sound good okay thank you well i guess since i'm next i have the concern as far as the tools so the first concern that we had with what kind of dependency dependencies do the tools have and how should c handle missing tool dependencies so will it exit will it error or did you want to go on to the next tool maybe a log that it one of the tools is missing a dependency so yeah like if if you can keep going like go you know like if it's gonna run five tools and maybe three can't run because map crashed or something weird happened then go ahead and run those other ones you know but report to the user like ah this one can't run because it doesn't have the necessary arguments it needs sound good my next question did you guys have a prioritization of tools so did you want nmap to be the priority did you want uh uh nissa's to have the priority or do you guys have like a prioritization table uh we don't have a table it's just kind of like the way we do it so usually we'll kick off uh nmap and nessus those are the first steps and then based off of that the output of that that's when we start trying other scanners and x and vulnerability scanners and stuff so like if i ran uh if i ran uh nessus and nmap and i found two web servers then maybe i want i might want to try nicto because i might find something necessarily fine right but if i ram both of those and i see no web servers at all and i go ask the pm and he tells me no this is this doesn't have any web servers and i wouldn't even why would i want to try to run nicto against anything right okay so to summarize it uh nmap and uh missus should always be run first so just kind of that's the basis yeah but also like if i created a custom script that i want to run all the time like how would you know that or i want a custom script to take in what nmap spits out or i want a custom script to take in whatever some other tool spits out so like what i'm saying is i guess that that should be configurable okay sound good uh the next question that i have would be uh how how would the c handle the data dependencies between the tools so as far as um i guess it could go back to login or what is exported um like say whatever nmap um displays how are you going to section off or is it going to be at the end you know in a nice clean format or is this going to be as it as it happens it would be spit out uh well in terms of like what it looks like i guess that's like part of the gui uh you know playing around with how the gui is gonna look and what's the best way but in turn but i do it would be nice to have as soon as you get data show it even if the tool is not done so it need because like i think map will show you like how far along it's gone so showing the user that would be you know useful specific on a bigger network you know and it's been running forever like two hours and we're like is this thing done you know versus just you all you see is a little spinning it's going you know it'd be nice to see like well it's this far along would you like different break points as far as like um say 20 25 completed or what projected 25 percent give this amount information or you just want to continuously um well it it wouldn't say absolutely continuously polling but like some kind of a reasonable interval like don't do it every six hours you know maybe like every minute or something like that it would go you know asset map where are you or go ask another tool where are you or sometimes other tools just start spitting out data as it goes along okay sound good uh my next question would be um as far as personalized scripts what are some example tasks that that it would be able to perform or handle so it's pretty much constricted or is it is it free range or how would you how would you describe it well it has to be some kind of scanning and you know scanning tool scanning because it's the purpose of this is the scan right maybe maybe scanning for an exploit but like uh an example that i gave the other class is like let's say i'm on a network where each host communicates to other hosts using a proprietary protocol like a customized protocol and i built this tool specifically so i can dissect those messages so i can understand that that customized protocol right where i can send data and receive a message that's customized from that customized protocol and i can make sense of it so that would be like an example if that makes sense of a customized script that i would want that i would want to stick that i'd want to add to this tool okay so and um my next question would be uh since you're allowing personalized scripts uh what type of shell functionality would see support and what language would be mostly preferred or what would be supported with these personalized scripts really be anything i can run off the command line okay you know so like most scripts we build are like in python or in bash but i wouldn't want to just you know sometimes i could i guess i could like build one and see right and just run that so i would like that that should i should be able to do that you know just anything off the command line pretty much okay well that concludes my questions thank you does anybody have any questions about uh tools okay so let's go ahead and move on to the next concern user interface hello uh my first question is what functions or commands of the of the scanning enumeration tool should be in the gui uh considering most of the two specified in the rd are terminate terminal based applications um so like what do you mean in the gui so like really all the gui is doing is giving me a button to kick everything off uh to feed in the input those blacklist whitelist configuration data or even in a file that i can create right and then all those underlying tools will start running as soon as i press the go button and show me their output their results in the gui okay maybe even a but to do the so i can create that output xml file okay uh second question is what do you like and i like about tools and programs that you have used in the past oh well let's see damian alexis you guys want to answer yeah um i like when a tool clearly tells you um maybe what you need um it gives you immediate feedback if there's an error you know it tells you where it is you know that way you're not just you know running around you know trying to figure it out you know it gives you some guidance where to look at um some tools that i don't like is where it has just generic error messages um i guess like that that's the biggest one um and i guess also going to like progress right so there's something running in the background like a thread running or you know knowing where it is um how far along that process is those are things that i like to see yeah and similar to what damian said user feedback i think is really important and then also making the gui uh intuitive you know so if you see a text box making you know making guiding the user so they know exactly how the tool is supposed to be used what it's there for and yeah uh okay my dick question and then you touched on it a little bit but how should the scanning process be represented in the scanning animation too uh how should it be represented well like it would be nice to see where what what has been done what still hasn't run you know something's currently running how far along is it if it's even possible some of these tools don't give you that right okay and then my final question is how should output be represented represented presented in the scanning generation tool uh would it be like in a different tab external windows or a default text editor uh not in a default text editor that's not a good idea so like some properties of gui's that i don't like or like if it has pop-up windows so you can have all these weird windows floating around and sometimes you don't see them because there's a bigger window in front of it you know what i mean that's not a good idea uh if you break down units of data you you group it into small too small of pieces so i got to go click around everywhere to like to look at everything that's not good you know but then again if you like put everything in one there's no clicking around it's all on one huge window and there's all your data that could get overwhelming so it's kind of hard right to like say what's exactly right it all depends on the nature of the data and like alexis was saying like kind of guides you along uh that's all of my questions thank you does anybody else have any follow-up questions for uh user interface okay so let's go ahead and move on to the next section user uh yes um our first question is uh what technical background will the end user have uh you could assume that they're familiar with the underlying tools or at least somewhat familiar and that kind of bleeds into the next question uh what are the differences between the analysts at the dac as in uh like their backgrounds if their technical knowledge would be to be able to run the tool so you can assume we all have the similar technical knowledge that's kind of the point of this tool right is to is to uh standardize everything because not like we're all very technical but some people are stronger at other stuff than others some people are familiar with some tools more so than others you know what i mean so like this is that's kind of the point of this is to standardize that but like i don't think you should worry about like well this is a manager person and they're not technical at all like no everybody's gonna you should assume everybody's like in the same role [Music] like a pentester role okay that makes sense and uh for our last question how should the c tool handle multiple analysts working on the same uh machine at different plans so like i was saying earlier how we all each get our own drive with the customized image of cali on it so like i it's where like you you shouldn't have to worry about like where so there's one computer and there's three of us and sometimes i use it and sometimes damien uses it and sometimes alexis uses it like no so we're all gonna have our own instance so so like all that user managing user stuff like you don't have to worry about that all right thank you and uh that concludes my uh user questions does anybody else have any other follow-up questions uh for a user so let's go ahead and move on to extensibility uh hello um the first question i'm gonna ask is a three-part question so i guess i'll start with the first part which is uh when a new tool is added to c how would c handle configuration settings uh so when a new tool is added uh the person who adds it should know like what parameters it's gonna use before they run the scan right so they should also know the dependency it would have if it has any like it it's waiting for you know has to run nmap first and get the results in map or else it can't run like all that all of that stuff would be known beforehand and it would all be part of configuration argument stuff that we talked okay so configuration pass name and argument all would have to be resolved ahead of time right yes okay and i guess for my next question would be what protocols are in place that determine the security and reliability of a potentially new tool being added to the system yeah so like when we we have uh we curate our custom cali instance beforehand so like this shouldn't be the c tools job to like go and inspect a new some tool that you just added and go like is this safe you know like you can assume like if it's on if it's on that image it's safe okay thank you i got a custom python script on there you know it's safe okay um that's all the questions i have about extensibility does anybody else have any other follow-up questions for extensibility okay let's go ahead and move on to maintainability um hi can you hear could you hear me okay um so my question first question is i know you already talked about what languages should be supported um but like you said uh scripting or even c sharp is fine but um so this might be repeating it a little bit but what languages should be supported uh for the tools what languages like you're talking about customized scripts or uh yeah like um for what will the software needed to run these languages be provided like example interpreters um and if so should the s-e-s-e-a detect these interpreters automatically like if if i can run it from the command line without the c tool then you should be you know it doesn't like it shouldn't be part of the c tool to like go uh is there is python even on here you know like no if you can all i should do is just try to run it off the command line and take the output okay and as far as like this uh like what specific languages should be supported um specific languages that's why i was telling you like as long as you can run it off the command line okay all right okay yes you don't got to worry about like well c went in there and found out that this was it somebody wrote this in bb script so no you know that's not in my that's not in my list of approved languages so now like no no like if it's just something custom that someone made and i can run it off the command line tool then c should be able to run it too okay um the next question is um what if any are the restrictions on authentication and authorization for the seed tool i'm sorry i'm going to um we're going over maintainability uh it's question 34 to question 36 and i'm not seeing out of the questions that you're asking her from the list um hmm uh i'm sorry well i thought uh i thought this was for uh because i saw a question 49 and 50 on it so that's why uh so we go for the maintainability first and the technology restriction that will come a little later um so let's go back to question number 34. okay um so i'm sorry i mean i was just i was reading uh i thought that that was um so uh please uh elaborate on any specific documentation styles uh conventions or formats that need to be applied when writing the documentation for the c tool uh like formats or anything like that it'd be nice if it was within the tool so it had like a little help you know but in terms of formats like i don't know something we all can read that's easy and intuitive those are weird properties to say right like everybody wants that but i can't point you to a specific kind i really can't say just as long as it's it's all within the tool and hopefully clear okay um and for the technology restriction question oh i'm sorry uh to interrupt so maintainability let's finish 34 35 36 and then when we touch on the technology restriction section that's when we go to uh question number f uh 49 and 50. ah okay so the next question is uh how long should versioning be uh attract for the z tool and the c and and the tools and it's uh that it's using like how should versioning be tracked like you're talking about the versions of the c tool there that will be created uh yes well we have a gitlab server so i don't know what like what you guys will give us at the end is just some code and then you know we'll take care of the configuration management and all that so i don't think like i don't see how a bunch of code could like only you know it won't work with git lab okay um the next question is how should upgrades and patches to the ctool be handled and how should upgrades and patches to its tools um be handled so in terms of the upgrades and patches to the seat tool specifically i don't think you need to worry about any kind of you know functionality that it has to update itself like if we're gonna fix it we'll just go in there in the code and fix it but in terms of like well okay now nmap has a new you know there's a new version and it's you know in a different place or something like that so then maybe like i have to go into that configuration [Music] uh part and go point it to the newer map does that make sense yes okay so the final part um sorry to interrupt so the technology restriction will come back a little later um let's finish maintainability um there was i think ecker you might have a question about maintainability hello i just wanted to say like alex that the person is supposed to do maintainability just do it so it was before he said other questions but no it's nothing require for a new question right now okay cool thank you let's go ahead and go to performance hello can you hear me hello um okay in terms of performance um uh checking whether input would be acceptable by the tool can take a long time especially if you have a very large data set so how detailed would you like to see tool to scan any given input in the expense of time so i think that should be up to the user you know what i mean like uh if there's a capability if there's a functionality of a particular tool to be verbose or not not as verbose you know like maybe on a large network i would like to like not not as beaver both because it would take more time does that make sense and i can configure that yes okay um okay so what can affect performance of a scan uh the size of the network is the main main one like you know if i only have five hosts that's not that bad but if i have like 50 000 and then i did a really uh uh tcp syn scan so it has to do that three-way handshake for each host that's gonna take forever um what percentage should be tolerated as a trade-off for speed what what um what percent error should be tolerated as a trade-off for speech the percentage like uh so if it airs out you should tell me you know what i mean like got a percentage of an error um okay well i guess sorry go ahead so i see an error more so like when something crashes totally not like well i was trying to scan this one whole thing like it didn't work but i just went on to another host like usually tools you know don't do that and all this stuff is configurable right it's all configurable mostly for the most part in most tools and so like you should just let let the analysts worry about that okay that makes sense yeah and finally um how do we measure the performance that each analyst has done and what do the analysts expect to see in terms of their of the performance and time it takes well we want all our scans to take one second no that obviously isn't that's not feasible but just you know as fast as possible and if like like allow the analysts to be able to fine-tune their their scans which you know if the scanner if the particular tool that they're using allows you know that kind of fine tuning in in terms of the arguments that it takes like let us you know make the tool so we can put those little arguments in there to make it more aggressive scanner if we have a smaller number of hosts or since we got a real large number of hosts and we've got a lot of time you know i'll make it not as aggressive right all right okay i guess that would be a good thing for you guys to research is like how sca like how how these tools scan like sometimes they they'll spend a whole bunch of time on one on one host and but it'll find out more information but it takes more time right versus like well i'm just going to go it's a really light pink scan all i do is hit it with peeing and i know it's there okay cool and then move on okay does anybody have any follow-up questions for um performance okay let's go ahead and move to the next section uh cons the concern parallelism uh hi can you guys hear me yes okay awesome so uh i know you you touched a little bit of earlier about wanting to run uh scans at the same time uh is there a maximum number of threads that we can run now concurrently yeah so i was like still in the other class 20. we'll just start we'll just stop at 20. stop at 20. awesome and then now carrying number oh i'm sorry about that uh and then is there a a maximum number of scans that we can run at uh concurrently at the same time like do you say like maybe for example only only four we only want to run nmap and then maybe uh one of the other scans at the same time or or however many we can fit in 20. well i would say it'd be good to like let the user pick okay he wants to run all of the ones that the tool knows about cool or he only wants to run i only want to run smb map that's it right gotcha and that's it does anybody have any follow-up questions for parallelism i have a clarified question to ask so there are two terms that have been used thread and also scanned are they the same thing or what is uh the definition of a scan because earlier you mentioned about utilizing multiple tools to do different types of scanning so what is the definition of a scanned and how is it different from uh the thread that is being the term thread mentioned in the rdd so we what we meant there is let's uh let's try to get multiple so a scan is like let's say i open the command prompt and i typed in you know durb and then gave it a url and then hit go so that's going okay cool and then i open another terminal and then i type nicto and then i give it that same url then i type go okay now they're both running concurrently right and they might take a while both of them but they're still both running simultaneously so that you know i didn't like hit i didn't go and run durb and then wait till it finished and then type in nikto and then run that like that that's more serial right so the the point of having threads is so we can run things concurrently like that like we do now usually sometimes we can't do that sometimes we gotta wait for the output of of one of those like end maps until we can run smb map sometimes things are like that but the whole point of that we're talking about parallelism and threads and things is so we would like you to put one like just like i did on the command line like that uh dur command in one thread and then the nicto command and another thread and like send them both to start executing so to follow on that um the context of a scanned could also be a serial uh earlier you mentioned about one two depending on another um that could be another type of scan so scan is not simply just executing one tool some scans might involve multiple tools running in a sequence is that correct uh yeah okay yeah i see what you mean by how scan can be confusing so like you're you're talking about like okay i open the c tool and i click go and it's really gonna run like four or five tools is that whole thing considered a scan or is each tool that it runs individually considered a scan uh well what i would consider a scan is each one of the individual ones okay yeah okay let's go ahead and go to environment so we're going back to eric yes what if any are the restrictions on the operating system that the c tool needs to support so that art like i was saying before operating systems cal it's a linux right we want to make it run on linux specifically kali linux [Music] um i guess if it has any kind of weird dependencies so like as you're well i guess that's more so in the software 2 class but like so in terms of the underlying tools you should just assume that they're that they work so the the you know you don't gotta take into consideration well do i gotta go look up dependencies or make sure dependencies are there those will all be there in terms of those underlying tools that you're that you're using okay and what type of application will c be would it be a web application desktop mobile um well it probably won't be mobile since we have hard drives and you know debt laptops but in terms of whether it's a web app or a desktop app or anything like that i guess that's up to the design like we're open to to client server model stuff but really i don't see this being used or being used in a networked way so it's not like okay i ran a scan and then i want to share it with alexis so we all plug in a switch and then i share my data with her like it's we're not gonna it's all just gonna be standalone if that makes sense yeah all right and uh lastly what kind of posix compliance should we expect from the environment the tool is executed in so it's whatever kali linux just as long as you can get it to run on a kali linux the re the most recent rolling kali linux version you can get it to run on that it should be good all right perfect thank you that concludes uh the environment concerns okay so let's go ahead and jump to technology restriction uh question 47 hello um what if any are the restrictions on internet access for c and its tools no internet access at all none none and question 48 would be what if any are the restrictions on using certain open source tools for scanning and enumeration portion of c as long as you can get it to run on cali because some tools are just built specifically for windows or they're old and they won't run on cali kelly's weird like it's very it's a different kind of operating system so you can get it to run on there then that's your restraint okay okay so the next two questions 49 and 50 uh vince did we touch on the restrictions on authentication authorization already yeah like there's no there's you don't gotta worry about users okay so let's go to the last question which is 51. uh so uh earlier you mentioned that you wanted some of the data that the airlock kicked out to be stored in a database uh is there a specific database that you guys use um i would recommend a nosql database okay uh a free one so this is this is with any software that you use third party uh open source it's it's being maintained so like if i go on github and look at the last uh push was like in 2015 that's not good right because nobody's done anything to it in five years and uh it obviously runs on linux so those are kind of the guidelines okay thank you include a database don't make so don't keep the data in a flat file don't keep it in a weird excel file you know don't keep it in us microsoft sql or any we need to pay for license that makes sense yes definitely thank you so that concludes our interview uh thank you vince uh damian alexis for coming to class today to speak with all of us about the project and answer our questions um and thanks everybody for coming to class um i will see you guys on tuesday if you guys have any questions about the interview report or the content being described in the interview uh contact ben am myself and we'll go ahead and help you guys out thanks everybody have a good weekend bye thank you bye thank you thank you
!